{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee40835-17fd-40fa-b361-489fd3b80b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import threading\n",
    "import tempfile\n",
    "import uuid\n",
    "import time\n",
    "import whisper\n",
    "import customtkinter as ctk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, ttk\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_groq import ChatGroq\n",
    "from PIL import Image, ImageTk\n",
    "from customtkinter import CTkImage\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b25300c4-8ded-44c9-85f6-f8e17b3f794a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string expression part cannot include a backslash (283306850.py, line 38)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 38\u001b[1;36m\u001b[0m\n\u001b[1;33m    f.write(f\"file '{path.replace('\\\\', '/')}\\n\")\u001b[0m\n\u001b[1;37m                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m f-string expression part cannot include a backslash\n"
     ]
    }
   ],
   "source": [
    "# ------------------ Utility Functions ------------------\n",
    "def _parse_srt_time(t):\n",
    "    try:\n",
    "        h, m, s_ms = t.split(\":\")\n",
    "        if \",\" in s_ms:\n",
    "            s, ms = s_ms.split(\",\")\n",
    "            return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000\n",
    "        else:\n",
    "            return int(h) * 3600 + int(m) * 60 + float(s_ms)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        m, s = t.split(\":\")\n",
    "        return int(m) * 60 + float(s)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        return float(t)\n",
    "    except:\n",
    "        raise ValueError(f\"Unrecognized timestamp format: {t}\")\n",
    "\n",
    "def format_time(seconds):\n",
    "    h = int(seconds // 3600)\n",
    "    m = int((seconds % 3600) // 60)\n",
    "    s = seconds % 60\n",
    "    return f\"{h:02}:{m:02}:{s:06.3f}\".replace(\".\", \",\")\n",
    "\n",
    "# ------------------ FFmpeg Functions ------------------\n",
    "def concatenate_videos(video_paths, output_filepath):\n",
    "    try:\n",
    "        if not video_paths:\n",
    "            return \"‚ùå Error: No video clips provided.\", None\n",
    "        ffmpeg_path = \"C:\\\\ffmpeg\\\\ffmpeg.exe\"\n",
    "        temp_dir = tempfile.gettempdir()\n",
    "        list_file_path = os.path.join(temp_dir, f\"concat_list_{uuid.uuid4().hex[:8]}.txt\")\n",
    "        with open(list_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for path in video_paths:\n",
    "                f.write(f\"file '{path.replace('\\\\', '/')}\\n\")\n",
    "        command = [\n",
    "            ffmpeg_path, \"-y\", \"-f\", \"concat\", \"-safe\", \"0\",\n",
    "            \"-i\", list_file_path, \"-c\", \"copy\", output_filepath\n",
    "        ]\n",
    "        result = subprocess.run(command, capture_output=True, text=True)\n",
    "        os.remove(list_file_path)\n",
    "        if result.returncode != 0:\n",
    "            return f\"‚ùå FFmpeg error:\\n{result.stderr}\", None\n",
    "        return f\"‚úÖ Concatenated video saved to: {output_filepath}\", output_filepath\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Exception during concatenation: {str(e)}\", None\n",
    "\n",
    "# ------------------ LLM Setup ------------------\n",
    "os.environ[\"GROQ_API_KEY\"] = \"Your_API_Key\"\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0.7)\n",
    "\n",
    "general_template = \"\"\"\n",
    "You are Vivi, an expert and friendly video assistant chatbot.\n",
    "You are having an ongoing conversation with the user. You have access to a full transcript of a video only when it is uploaded. If the user‚Äôs question is about the video, answer helpfully and refer to timestamps if relevant.\n",
    "If the question is general and not related to the video, just respond helpfully like a normal assistant.\n",
    "---\n",
    "Conversation History:\n",
    "{context}\n",
    "---\n",
    "Full Transcript of the Video:\n",
    "{transcript}\n",
    "---\n",
    "User:\n",
    "{question}\n",
    "---\n",
    "Vivi:\n",
    "\"\"\"\n",
    "\n",
    "clipping_template = \"\"\"\n",
    "You are an expert video analysis assistant. Given a user query and the transcript of a video with timestamps, identify all timestamp ranges where the video content is relevant to the query. Return the result as a list of timestamp ranges (start and end times in seconds) and a brief explanation of why each range is relevant.\n",
    "\n",
    "Return timestamps as plain numbers with two decimal places (e.g., 31.00, 45.00) without brackets or other characters. Ensure the format is consistent. Ensure end_time is greater than start_time and both are non-negative.\n",
    "\n",
    "Query: {query}\n",
    "Transcript: {transcript}\n",
    "\n",
    "Return the result in the following format and each range and its explanation must be on separate lines:\n",
    "- Range: start_time - end_time\n",
    "- Range: start_time - end_time\n",
    "  Relevance: [Brief explanation of why this range is relevant to the query]\n",
    "\"\"\"\n",
    "\n",
    "prompt_general = ChatPromptTemplate.from_template(general_template)\n",
    "prompt_clipping = ChatPromptTemplate.from_template(clipping_template)\n",
    "chain_general = prompt_general | llm\n",
    "chain_clipping = prompt_clipping | llm\n",
    "\n",
    "# ------------------ Vivi GUI Class ------------------\n",
    "class ViviChatbot:\n",
    "    def __init__(self):\n",
    "        # Use light appearance mode\n",
    "        ctk.set_appearance_mode(\"light\")\n",
    "        ctk.set_default_color_theme(\"blue\")\n",
    "\n",
    "        # Create root and set background\n",
    "        self.root = ctk.CTk()\n",
    "        self.root.configure(fg_color=\"#FFFFFF\")\n",
    "        self.root.title(\"ClipQuery- Video Chatbot\")\n",
    "        self.root.geometry(\"900x650\")\n",
    "\n",
    "        self.video_path = \"\"\n",
    "        self.context = \"\"\n",
    "        self.transcript_segments = []\n",
    "        self.full_transcript_text = \"\"\n",
    "        self.audio_process = None\n",
    "\n",
    "        logo_frame = ctk.CTkFrame(self.root, fg_color=\"#FFFFFF\")\n",
    "        logo_frame.pack(padx=20, pady=(10, 0), anchor=\"w\")\n",
    "\n",
    "        self.logo_image = CTkImage(Image.open(\"vivi_logo_1.png\"), size=(40, 40))\n",
    "        logo_label = ctk.CTkLabel(logo_frame, image=self.logo_image, text=\"\")\n",
    "        logo_label.image = self.logo_image  # üîí Prevent TclError\n",
    "        logo_label.pack(side=\"left\", padx=(0, 10))\n",
    "\n",
    "        logo_text = ctk.CTkLabel(\n",
    "            logo_frame,\n",
    "            text=\"ClipQuery\",\n",
    "            font=(\"Arial\", 28, \"bold\"),\n",
    "            text_color=\"#1a2238\",\n",
    "            anchor=\"w\",  # Make sure it's left-anchored\n",
    "            justify=\"left\"\n",
    "        )\n",
    "        logo_text.pack(side=\"left\")\n",
    "        \n",
    "        # Chat display frame\n",
    "        self.chat_frame = ctk.CTkScrollableFrame(self.root, width=880, height=500, fg_color=\"#FFFFFF\")\n",
    "        self.chat_frame.pack(padx=20, pady=(5, 10), fill=\"both\", expand=True)\n",
    "        self.scrollable_frame = self.chat_frame\n",
    "\n",
    "        # Entry field frame\n",
    "        self.entry_frame = ctk.CTkFrame(self.root, fg_color=\"#FFFFFF\")\n",
    "        self.entry_frame.pack(pady=(0, 5), fill=\"x\", padx=20)\n",
    "\n",
    "        self.user_entry = ctk.CTkEntry(self.entry_frame, placeholder_text=\"Ask Vivi...\", width=700, height=40, font=(\"Arial\", 16))\n",
    "        self.user_entry.pack(side=\"left\", fill=\"x\", expand=True, padx=(0, 10))\n",
    "        self.user_entry.bind(\"<Return>\", lambda e: self.send_message())\n",
    "\n",
    "        self.send_btn = ctk.CTkButton(self.entry_frame, text=\"Send\", command=self.send_message, fg_color=\"#1a2238\", width=160, height=40, font=(\"Arial\", 16))\n",
    "        self.send_btn.pack(side=\"right\")\n",
    "\n",
    "        # Buttons for upload, input video, and final video\n",
    "        self.btn_frame = ctk.CTkFrame(self.root, fg_color=\"#FFFFFF\")\n",
    "        self.btn_frame.pack(pady=(0, 10))\n",
    "\n",
    "        self.upload_btn = ctk.CTkButton(self.btn_frame, text=\"üìÇ Upload Video\", command=self.browse_video, fg_color=\"#1a2238\", width=160, height=30, font=(\"Arial\", 16))\n",
    "        self.upload_btn.pack(side=\"left\", padx=5)\n",
    "\n",
    "        self.input_video_btn = ctk.CTkButton(self.btn_frame, text=\"‚ñ∂Ô∏èInput Video\", command=self.play_input_video, fg_color=\"#1a2238\", width=160, height=30, font=(\"Arial\", 16))\n",
    "        self.input_video_btn.pack(side=\"left\", padx=5)\n",
    "\n",
    "        self.final_video_btn = ctk.CTkButton(self.btn_frame, text=\"üé¨ Final Video\", command=self.play_final_video, fg_color=\"#1a2238\", width=160, height=30, font=(\"Arial\", 16))\n",
    "        self.final_video_btn.pack(side=\"left\", padx=5)\n",
    "        \n",
    "        # Initial welcome message\n",
    "        self.display_message(\"system\", \"üé¨ Welcome to Vivi!\\nType 'exit' to quit.\\nUse format `Clip:<your query>` for semantic editing.\")\n",
    "\n",
    "    def typewriter_effect(self, sender, message):\n",
    "        # Outer frame to control side alignment\n",
    "        outer_frame = ctk.CTkFrame(self.scrollable_frame, fg_color=\"#FFFFFF\")\n",
    "        outer_frame.pack(fill=\"x\", padx=10, pady=5)\n",
    "\n",
    "        # Inner chat bubble with side-specific color\n",
    "        bubble_frame = ctk.CTkFrame(\n",
    "            outer_frame,\n",
    "            fg_color=\"#3a0e2e\" if sender.lower() == \"vivi\" else \"#1B263B\",\n",
    "            corner_radius=12\n",
    "        )\n",
    "        if sender.lower() == \"vivi\":\n",
    "            bubble_frame.pack(anchor=\"w\", padx=5)\n",
    "        else:\n",
    "            bubble_frame.pack(anchor=\"e\", padx=5)\n",
    "\n",
    "        # Name label (optional, can be hidden if not needed)\n",
    "        name_label = ctk.CTkLabel(\n",
    "            bubble_frame,\n",
    "            text=sender + \":\",\n",
    "            font=(\"Arial\", 12, \"bold\"),\n",
    "            text_color=\"#F0F0F0\"\n",
    "        )\n",
    "        name_label.pack(anchor=\"w\", padx=8, pady=(6, 0))\n",
    "\n",
    "        # Message label for typewriter text\n",
    "        message_label = ctk.CTkLabel(\n",
    "            bubble_frame,\n",
    "            text=\"\",\n",
    "            font=(\"Arial\", 20, \"normal\"),\n",
    "            wraplength=500,\n",
    "            justify=\"left\",\n",
    "            text_color=\"#F0F0F0\"\n",
    "        )\n",
    "        message_label.pack(anchor=\"w\", padx=8, pady=(0, 8))\n",
    "\n",
    "        # Scroll to bottom before typing\n",
    "        self.root.update_idletasks()\n",
    "        self.chat_frame._parent_canvas.yview_moveto(1.0)\n",
    "\n",
    "        # Typewriter animation\n",
    "        current_text = \"\"\n",
    "        for word in message.split():\n",
    "            current_text += word + \" \"\n",
    "            message_label.configure(text=current_text)\n",
    "            self.root.update_idletasks()\n",
    "            self.chat_frame._parent_canvas.yview_moveto(1.0)\n",
    "            time.sleep(0.04)\n",
    "    \n",
    "    def display_message(self, sender, message):\n",
    "        outer_frame = ctk.CTkFrame(self.chat_frame, fg_color=\"#FFFFFF\")\n",
    "        outer_frame.pack(fill=\"x\", padx=10, pady=5)\n",
    "\n",
    "        bubble = ctk.CTkFrame(\n",
    "            outer_frame,\n",
    "            corner_radius=15,\n",
    "            fg_color=\"#3a0e2e\" if sender.lower() != \"user\" else \"#1a2238\"\n",
    "        )\n",
    "\n",
    "        if sender.lower() == \"user\":\n",
    "            bubble.pack(anchor=\"e\", padx=5)\n",
    "        else:\n",
    "            bubble.pack(anchor=\"w\", padx=5)\n",
    "\n",
    "        label = ctk.CTkLabel(\n",
    "            bubble,\n",
    "            text=f\"{message}\",\n",
    "            wraplength=700,\n",
    "            font=(\"Arial\", 20, \"normal\"),\n",
    "            justify=\"left\",\n",
    "            text_color=\"#F0F0F0\"\n",
    "        )\n",
    "        label.pack(anchor=\"w\", padx=10, pady=5)\n",
    "\n",
    "\n",
    "    def clip_video(self, start_time, end_time):\n",
    "        try:\n",
    "            if start_time >= end_time:\n",
    "                self.display_message(\"system\", f\"‚ö† Invalid clip range: {start_time} >= {end_time}\")\n",
    "                return \"Invalid time range\", None\n",
    "            clip_filename = f\"clip_{uuid.uuid4().hex[:8]}.mp4\"\n",
    "            output_path = os.path.join(tempfile.gettempdir(), clip_filename)\n",
    "            subprocess.run([\n",
    "                \"ffmpeg\", \"-y\", \"-ss\", str(start_time), \"-to\", str(end_time),\n",
    "                \"-i\", self.video_path, \"-c\", \"copy\", output_path\n",
    "            ], check=True)\n",
    "            return f\"üé¨ Video clip saved to {output_path}\", output_path\n",
    "        except Exception as e:\n",
    "            self.display_message(\"system\", f\"‚ùå Error clipping video: {e}\")\n",
    "\n",
    "    def transcribe_video(self, video_path):\n",
    "            base = os.path.splitext(os.path.basename(video_path))[0]\n",
    "            dir_ = os.path.dirname(video_path)\n",
    "            txt_path = os.path.join(dir_, f\"{base}.txt\")\n",
    "            srt_path = os.path.join(dir_, f\"{base}.srt\")\n",
    "\n",
    "            # Check if already transcribed\n",
    "            if os.path.exists(txt_path) and os.path.exists(srt_path):\n",
    "                with open(srt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    blocks = f.read().strip().split(\"\\n\\n\")\n",
    "                with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    timed_transcript = f.read().strip()\n",
    "                segments = []\n",
    "                for block in blocks:\n",
    "                    lines = block.split(\"\\n\")\n",
    "                    if len(lines) >= 3:\n",
    "                        times = lines[1].split(\" --> \")\n",
    "                        start = _parse_srt_time(times[0])\n",
    "                        end = _parse_srt_time(times[1])\n",
    "                        text = \" \".join(lines[2:])\n",
    "                        segments.append({\"start\": start, \"end\": end, \"text\": text})\n",
    "                return timed_transcript, segments\n",
    "\n",
    "            # Use Groq Whisper API\n",
    "            self.display_message(\"system\", \"üîç Running Whisper (large-v3) for transcription...\")\n",
    "\n",
    "            api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "            if not api_key:\n",
    "                raise ValueError(\"GROQ_API_KEY is not set in environment variables.\")\n",
    "\n",
    "            client = Groq(api_key=api_key)\n",
    "\n",
    "            with open(video_path, \"rb\") as file:\n",
    "                transcription = client.audio.transcriptions.create(\n",
    "                    file=file,\n",
    "                    model=\"whisper-large-v3\",\n",
    "                    prompt=\"\",  # You can provide custom prompt if needed\n",
    "                    response_format=\"verbose_json\",\n",
    "                    timestamp_granularities=[\"segment\"],\n",
    "                    language=\"en\",\n",
    "                    temperature=0.0\n",
    "                )\n",
    "\n",
    "            segments = []\n",
    "            timed_transcript = \"\"\n",
    "            for seg in transcription.segments:\n",
    "                start = seg[\"start\"]\n",
    "                end = seg[\"end\"]\n",
    "                text = seg[\"text\"]\n",
    "                segments.append({\"start\": start, \"end\": end, \"text\": text})\n",
    "                timed_transcript += f\"[{start:.2f} - {end:.2f}] {text}\\n\"\n",
    "\n",
    "            # Save to SRT\n",
    "            with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                for i, seg in enumerate(segments):\n",
    "                    f.write(f\"{i+1}\\n{format_time(seg['start'])} --> {format_time(seg['end'])}\\n{seg['text']}\\n\\n\")\n",
    "\n",
    "            # Save to TXT\n",
    "            with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(timed_transcript)\n",
    "\n",
    "            return timed_transcript, segments\n",
    "\n",
    "    def send_message(self):\n",
    "        user_input = self.user_entry.get()\n",
    "        if user_input.strip().lower() == \"exit\":\n",
    "            self.root.destroy()\n",
    "            return\n",
    "        self.display_message(\"user\", user_input)\n",
    "        self.user_entry.delete(0, tk.END)\n",
    "        self.user_entry.configure(state=\"disabled\")\n",
    "        self.send_btn.configure(state=\"disabled\")\n",
    "\n",
    "        def extract_content(response):\n",
    "            return str(response.content) if hasattr(response, \"content\") else str(response)\n",
    "\n",
    "        def run_bot():\n",
    "            if user_input.lower().startswith(\"clip:\"):\n",
    "                query = user_input[len(\"clip:\"):].strip()\n",
    "                response = chain_clipping.invoke({\"query\": query, \"transcript\": self.transcript_segments})\n",
    "                response_text = extract_content(response)\n",
    "\n",
    "                video_clips = []\n",
    "                for line in response_text.strip().split(\"\\n\"):\n",
    "                    if line.startswith(\"- Range: \"):\n",
    "                        parts = line[len(\"- Range: \"):].split(\" - \")\n",
    "                        try:\n",
    "                            start = float(parts[0])\n",
    "                            end = float(parts[1])\n",
    "                            msg, clip_path = self.clip_video(start, end)\n",
    "                            if clip_path:\n",
    "                                video_clips.append(clip_path)\n",
    "                        except:\n",
    "                            continue\n",
    "                if video_clips:\n",
    "                    msg, out = concatenate_videos(\n",
    "                        video_clips,\n",
    "                        output_filepath=os.path.join(os.path.dirname(self.video_path), \"final_output.mp4\")\n",
    "                    )\n",
    "                    self.display_message(\"Vivi\", msg)\n",
    "            else:\n",
    "                response = chain_general.invoke({\n",
    "                    \"context\": self.context,\n",
    "                    \"question\": user_input,\n",
    "                    \"transcript\": self.transcript_segments\n",
    "                })\n",
    "                response_text = extract_content(response)\n",
    "                self.typewriter_effect(\"Vivi\", response_text)\n",
    "                self.context += f\"\\nUser: {user_input}\\nAI: {response_text}\\n\"\n",
    "\n",
    "            self.user_entry.configure(state=\"normal\")\n",
    "            self.send_btn.configure(state=\"normal\")\n",
    "            self.user_entry.focus()\n",
    "\n",
    "        threading.Thread(target=run_bot).start()\n",
    "\n",
    "    def browse_video(self):\n",
    "        self.video_path = filedialog.askopenfilename(filetypes=[(\"Video Files\", \"*.mp4 *.mov *.avi\")])\n",
    "        if not self.video_path:\n",
    "            return\n",
    "        self.display_message(\"system\", f\"üìÅ Selected video: {os.path.basename(self.video_path)}\")\n",
    "        def process_video():\n",
    "            self.full_transcript_text, self.transcript_segments = self.transcribe_video(self.video_path)\n",
    "            self.display_message(\"system\", \"‚úÖ Transcription completed!\")\n",
    "        threading.Thread(target=process_video).start()\n",
    "\n",
    "    def play_input_video(self):\n",
    "        if not self.video_path:\n",
    "            self.display_message(\"system\", \"‚ö†Ô∏è No video uploaded yet. Upload a video first.\")\n",
    "            return\n",
    "        if self.audio_process and self.audio_process.poll() is None:\n",
    "            self.audio_process.terminate()\n",
    "        try:\n",
    "            self.audio_process = subprocess.Popen([\"ffplay\", \"-autoexit\", \"-loglevel\", \"quiet\", self.video_path])\n",
    "        except Exception as e:\n",
    "            self.display_message(\"system\", f\"‚ùå Failed to play input video: {e}\")\n",
    "\n",
    "    def play_final_video(self):\n",
    "        final_output = os.path.join(os.path.dirname(self.video_path), \"final_output.mp4\")\n",
    "        if not os.path.exists(final_output):\n",
    "            self.display_message(\"system\", \"‚ö†Ô∏è No final video available. Generate a clipped video first.\")\n",
    "            return\n",
    "        if self.audio_process and self.audio_process.poll() is None:\n",
    "            self.audio_process.terminate()\n",
    "        try:\n",
    "            self.audio_process = subprocess.Popen([\"ffplay\", \"-autoexit\", \"-loglevel\", \"quiet\", final_output])\n",
    "        except Exception as e:\n",
    "            self.display_message(\"system\", f\"‚ùå Failed to play final video: {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        self.root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = ViviChatbot()\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b272d99-7487-4af0-8971-5b6b3d0c47dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
